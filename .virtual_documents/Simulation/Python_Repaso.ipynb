import math
import matplotlib.pyplot as plt
import random
from collections import Counter



import matplotlib.pyplot as plt
from collections import Counter

class RandomVariableSimulator:
    """
    Clase base general para simulación de variables aleatorias.

    Las clases hijas deben definir:
        - generator(self)
        - self.kind = "discrete" o "continuous"
    """

    def __init__(self):
        self.kind = None  # Lo define la clase hija

    def generator(self):
        raise NotImplementedError(
            "Debes implementar el método generator en la clase hija"
        )

    def sample(self, n):
        return [self.generator() for _ in range(n)]

    def plot(self, n=1000, rango=None, bins=50):

        if self.kind is None:
            raise ValueError("Debes definir self.kind como 'discrete' o 'continuous'")

        data = self.sample(n)
        plt.figure()

        if self.kind == "discrete":

            counts = Counter(data)
            x_vals = sorted(counts.keys())
            probs = [counts[x] / n for x in x_vals]
            labels = [str(x) for x in x_vals]
            plt.bar(labels, probs)
            plt.ylabel("Probabilidad")
            

        elif self.kind == "continuous":

            plt.hist(data, bins=bins, density=True, range=rango)
            plt.ylabel("Densidad")

        else:
            raise ValueError("self.kind debe ser 'discrete' o 'continuous'")

        plt.xlabel("Valores")
        plt.show()






class GLC(RandomVariableSimulator):
    """
    Generador Lineal Congruencial (GLC)

    X_{n+1} = (a X_n + c) mod m
    U_n = X_n / m
    """

    def __init__(self, m=2**31 - 1, a=7**5, c=0, seed=1):
        super().__init__()

        self.m = m
        self.a = a
        self.c = c
        self.state = seed

        self.kind = "continuous"

    def generator(self):

        # Fórmula correcta
        self.state = (self.a * self.state + self.c) % self.m

        return self.state / self.m



glc = GLC(seed=16230)
glc.plot(50000)


glc = GLC(seed=15672,a=2**9-1,c=0,m=2**5-1)
glc.plot(10000)


#Generar números uniformes
random.seed(23)

for _ in range(10):
    print(random.random())








class Bernoulli(RandomVariableSimulator):
    """
    Simulación de una variable aleatoria Bernoulli(p)

    P(X = 1) = p
    P(X = 0) = 1 - p
    """

    def __init__(self, p):
        super().__init__()

        if not (0 <= p <= 1):
            raise ValueError("El parámetro p debe estar en [0,1]")

        self.p = p
        self.kind = "discrete"

    def generator(self):
        u = random.random()
        return 1 if u < self.p else 0



bern = Bernoulli(0.5)
bern.plot(5000)


class DiscretaGeneral(RandomVariableSimulator):
    """
    Generador para una variable aleatoria discreta general.

    Valores posibles: x1, x2, ..., xn
    Probabilidades:  p1, p2, ..., pn   con sum(pi)=1

    Usa U ~ Uniforme(0,1) y el método de probabilidades acumuladas.
    """

    def __init__(self, valores, probabilidades):
        super().__init__()

        if len(valores) != len(probabilidades):
            raise ValueError("valores y probabilidades deben tener la misma longitud")

        if not abs(sum(probabilidades) - 1) < 1e-10:
            raise ValueError("Las probabilidades deben sumar 1")

        if any(p < 0 for p in probabilidades):
            raise ValueError("Las probabilidades deben ser no negativas")

        self.valores = valores
        self.probabilidades = probabilidades
        self.kind = "discrete"

        # Construcción de probabilidades acumuladas
        self.acumuladas = []
        acumulado = 0
        for p in probabilidades:
            acumulado += p
            self.acumuladas.append(acumulado)

    def generator(self):

        u = random.random()

        for valor, prob_acum in zip(self.valores, self.acumuladas):
            if u <= prob_acum:
                return valor





valores = [-1,0.1,2.0,-4]
probs = [0.2, 0.3, 0.1, 0.4]

dg = DiscretaGeneral(valores, probs)
dg.plot(5000)






class UniformeAB(RandomVariableSimulator):
    """
    Generador Uniforme(a,b)
    """

    def __init__(self, a, b):
        super().__init__()

        if b <= a:
            raise ValueError("Se requiere a < b")

        self.a = a
        self.b = b
        self.kind = "continuous"

    def generator(self):
        u = random.random()
        return (self.b - self.a)*u + self.a



u = UniformeAB(2, 5)
u.plot(50000)





class Cauchy(RandomVariableSimulator):
    """
    Generador de una variable Cauchy(mu, gamma)

    Densidad:
        f(x) = 1 / [pi * gamma * (1 + ((x-mu)/gamma)^2)]
    """

    def __init__(self, mu=0, gamma=1):
        super().__init__()

        if gamma <= 0:
            raise ValueError("gamma debe ser positiva")

        self.mu = mu
        self.gamma = gamma
        self.kind = "continuous"

    def generator(self):

        u = random.random()

        return self.mu + self.gamma * math.tan(math.pi * (u - 0.5))


c = Cauchy(0.1)
c.plot(5000,rango=(-10,10))





class Exponencial(RandomVariableSimulator):
    """
    Generador de una variable Exponencial(lambda)

    Densidad:
        f(x) = lambda * exp(-lambda x),   x >= 0
    """

    def __init__(self, lambd = 1 ):
        super().__init__()

        if lambd <= 0:
            raise ValueError("lambda debe ser positiva")

        self.lambd = lambd
        self.kind = "continuous"

    def generator(self):

        u = random.random()

        return -math.log(u) / self.lambd


exp = Exponencial(lambd=2)

exp.plot(10000)





class Gamma(RandomVariableSimulator):
    """
    Generador Gamma(k, lambda) con k entero positivo
    usando el producto de uniformes.
    """

    def __init__(self, k, lam):
        super().__init__()

        if k <= 0 or int(k) != k:
            raise ValueError("k debe ser entero positivo")

        if lam <= 0:
            raise ValueError("lambda debe ser positiva")

        self.k = int(k)
        self.lam = lam
        self.kind = "continuous"

    def generator(self):
        
        total = 0.0
        
        for _ in range(self.k):
            u = random.random()
            total += -math.log(u)
        
        return total / self.lam


g = Gamma(4, 2)
g.plot(10000)





class Binomial(RandomVariableSimulator):
    """
    Generador Binomial(n, p) como suma de n Bernoulli(p)
    """

    def __init__(self, n, p):
        super().__init__()

        if n <= 0 or int(n) != n:
            raise ValueError("n debe ser entero positivo")

        if not (0 <= p <= 1):
            raise ValueError("p debe estar en [0,1]")

        self.n = int(n)
        self.p = p
        self.kind = "discrete"

    def generator(self):

        total = 0

        for _ in range(self.n):
            if random.random() < self.p:
                total += 1

        return total



Bin = Binomial(4, 0.5)
Bin.plot(10000)





class LogUniforme(RandomVariableSimulator):
    """
    Variable con densidad f(x)=1/x
    en el intervalo [1, e]
    """

    def __init__(self):
        super().__init__()
        self.kind = "continuous"

    def generator(self):

        u = random.random()
        return math.exp(u)



x = LogUniforme()
x.plot(10000, rango=(1, math.e))





import numpy.random as numprand


numprand.binomial(n=3,p=0.1,size=10)


numprand.exponential?


numprand.triangular?





import torch


# ============================================================
# CREAR UNA DISTRIBUCIÓN NORMAL ESTÁNDAR N(0,1)
# ============================================================

normal = torch.distributions.Normal(0,1)

# Tensor escalar (un solo valor)
x = torch.tensor(0)

# cdf(x) = P(X <= x)
# Para una normal estándar, cdf(0) ≈ 0.5
print(normal.cdf(x))
# log_prob(x) = log(f(x)) donde f es la densidad
print(normal.log_prob(x))


# Ahora x es un vector
x = torch.tensor([-1,0,1])

print(normal.cdf(x))
print(normal.log_prob(x))


normal.sample?



normal.sample(torch.Size([10]))


 # Fijamos la semilla para reproducibilidad
torch.random.manual_seed(1)
# 10x2 muestras independientes de N(0,1)
normal.sample(torch.Size([10,2]))


 #Ahora creamos varias normales al mismo tiempo.
# mu tiene 3 valores -> tendremos 3 normales distintas.
mu =  torch.Tensor([-1.0,0.0,5.0])

sigma = torch.Tensor([1])

normal2 = torch.distributions.Normal(mu,sigma)

muestras = normal2.sample(torch.Size([1000]))

# Pedimos 1000 muestras.
# IMPORTANTE:
# El resultado tendrá dimensión [1000, 3]
# porque hay 3 distribuciones normales.
print(muestras)


muestras.mean(dim = 0)


mu =  torch.Tensor([-1.0,0.0,5.0])
sigma = torch.Tensor([1,3,4])
normal2 = torch.distributions.Normal(mu,sigma)
muestras = normal2.sample((10,))
print(muestras)


muestras.std(dim=0)


p = torch.tensor([0.5, 0.1])
bernoulli = torch.distributions.Bernoulli(p)

muestras = bernoulli.sample((10,))
print(muestras)
print(muestras.shape)


no
